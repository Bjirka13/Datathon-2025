# -*- coding: utf-8 -*-
"""predict.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HOFQsQ56obJo1c_RwV59tbB0RLw603LS

## Load New Data
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

LI_path = "/content/drive/MyDrive/Dataset/Datathon Project/LI-Small_Trans.csv.zip"

!unzip -q "{LI_path}" -d "./data"

LI = pd.read_csv("/content/data/LI-Small_Trans.csv")

"""## Preprocess new data"""

!pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.0.0+cpu.html

import pandas as pd
import numpy as np
import torch
from sklearn.preprocessing import LabelEncoder
import torch.nn.functional as F
from torch_geometric.data import Data
from torch_geometric.nn import GCNConv

for col in ['Receiving Currency', 'Payment Currency', 'Payment Format']:
    LI[col] = LabelEncoder().fit_transform(LI[col])

# Timestamp normalize
LI['Timestamp'] = pd.to_datetime(LI['Timestamp'])
LI['Timestamp'] = LI['Timestamp'].astype('int64') / 1e9
LI['Timestamp'] = (LI['Timestamp'] - LI['Timestamp'].min()) / (LI['Timestamp'].max() - LI['Timestamp'].min())

# Buat ID unik
LI['Sender_ID'] = LI['From Bank'].astype(str) + "_" + LI['Account']
LI['Receiver_ID'] = LI['To Bank'].astype(str) + "_" + LI['Account.1']

# Buat tabel node
senders = LI[['Sender_ID', 'From Bank']].rename(columns={'Sender_ID': 'Account', 'From Bank': 'Bank'})
receivers = LI[['Receiver_ID', 'To Bank']].rename(columns={'Receiver_ID': 'Account', 'To Bank': 'Bank'})
nodes = pd.concat([senders, receivers]).drop_duplicates('Account').reset_index(drop=True)
nodes['node_id'] = pd.factorize(nodes['Account'])[0]
nodes['Bank'] = LabelEncoder().fit_transform(nodes['Bank'])

# Agregasi Paid/Received per Currency
paid = LI[['Sender_ID', 'Amount Paid', 'Payment Currency']].rename(columns={'Sender_ID': 'Account'})
recv = LI[['Receiver_ID', 'Amount Received', 'Receiving Currency']].rename(columns={'Receiver_ID': 'Account'})

paid_agg = paid.groupby(['Account', 'Payment Currency'])['Amount Paid'].mean().unstack(fill_value=0)
recv_agg = recv.groupby(['Account', 'Receiving Currency'])['Amount Received'].mean().unstack(fill_value=0)

features = pd.concat([paid_agg, recv_agg], axis=1)
features.columns = [f"paid_{c}" if i < paid_agg.shape[1] else f"recv_{c}" for i, c in enumerate(features.columns)]
features = features.reset_index()
nodes = nodes.merge(features, on='Account', how='left').fillna(0)

# Waktu transaksi
LI['Hour'] = pd.to_datetime(LI['Timestamp'] * (LI['Timestamp'].max() - LI['Timestamp'].min()) + LI['Timestamp'].min(), unit='s').dt.hour
LI['DayOfWeek'] = pd.to_datetime(LI['Timestamp'] * (LI['Timestamp'].max() - LI['Timestamp'].min()) + LI['Timestamp'].min(), unit='s').dt.dayofweek
time_feat = LI[['Sender_ID', 'Hour', 'DayOfWeek']].rename(columns={'Sender_ID': 'Account'})
time_feat = time_feat.groupby('Account').mean().reset_index()
nodes = nodes.merge(time_feat, on='Account', how='left').fillna(0)

"""## Make Graph"""

x = torch.tensor(nodes.drop(columns=['Account', 'node_id']).values, dtype=torch.float)
account_to_id = dict(zip(nodes['Account'], nodes['node_id']))

LI['from_node'] = LI['Sender_ID'].map(account_to_id)
LI['to_node'] = LI['Receiver_ID'].map(account_to_id)

edges = LI.dropna(subset=['from_node', 'to_node']).copy()
edge_index = torch.tensor([
    edges['from_node'].astype(int).values,
    edges['to_node'].astype(int).values
], dtype=torch.long)

data = Data(x=x, edge_index=edge_index)

"""## Load Model"""

class GCN(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, out_channels)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return x

"""## Predict the new data"""

model = GCN(in_channels=x.shape[1], hidden_channels=64, out_channels=2)
model.load_state_dict(torch.load("model_gcn_aml.pth"))
model.eval()

with torch.no_grad():
    out = model(data)
    preds = out.argmax(dim=1).cpu().numpy()

"""## Save Prediction from new Data"""

nodes['Prediction'] = preds
nodes['Prediction Label'] = nodes['Prediction'].map({0: 'Legitimate', 1: 'Laundering'})
nodes[['Account', 'Prediction Label']].to_csv("prediction_result.csv", index=False)
print("Hasil prediksi disimpan")